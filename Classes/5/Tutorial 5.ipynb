{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 5 - Biologically motivated analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action = \"ignore\", category = FutureWarning)\n",
    "import os\n",
    "import os\n",
    "import copy\n",
    "import re\n",
    "import random\n",
    "import mygene\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sc.logging.print_header()\n",
    "sc.settings.n_jobs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check this is set correctly to '/home/<SUNetID>/BIOC281/Classes/5' on FarmShare\n",
    "# On Sherlock it should be /home/groups/<Group_Name>/BIOC281/Classes/5/\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the SmartSeq2 data and sort the cells alphanumerically\n",
    "adata = sc.read_csv(filename=os.path.join(pwd, 'krasnow_hlca_facs_counts.csv')).T\n",
    "adata = adata[adata.obs_names.sort_values()]\n",
    "\n",
    "# Read in the SmartSeq2 metadata and sort the cells alphanumerically\n",
    "tmp = pd.read_csv(filepath_or_buffer=os.path.join(pwd, 'krasnow_hlca_facs_metadata.csv'), index_col=0).sort_index()\n",
    "adata.obs = tmp.copy()\n",
    "\n",
    "# Stash counts in a new layer\n",
    "adata.layers['counts'] = adata.X.copy()\n",
    "\n",
    "# Normalize counts to counts per million, log them, and store the ln(counts per million + 1) in adata.raw.X\n",
    "sc.pp.normalize_total(adata, target_sum=1e6)\n",
    "sc.pp.log1p(adata)\n",
    "adata.raw = adata\n",
    "\n",
    "# Select highly variable genes\n",
    "sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=6, min_disp=0.5)\n",
    "\n",
    "# Center and scale log normalized expression values and run PCA\n",
    "sc.pp.scale(adata, max_value=10)\n",
    "\n",
    "# Write the SmartSeq2 object to an h5ad object\n",
    "adata.write(os.path.join(pwd, 'krasnow_hlca_facs_normalized.h5ad'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get a memory error running any of the code chunks below, \n",
    "click on \"Kernel\" above in the file menu and then click \"Restart Kernel and Clear All Outputs...\". \n",
    "After Kernel has restarted, run the three chunks of code on the very top within the section \"Load required packages\". \n",
    "After that skip the current section (Data ingest) and move directly to the next section below \"Load saved h5ad\". \n",
    "This ensures that memory requirements stay low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load saved h5ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the h5ad object, this seems to halve the memory usage\n",
    "adata = sc.read_h5ad(os.path.join(pwd, 'krasnow_hlca_facs_normalized.h5ad'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify differentially expressed genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):   \n",
    "    # Use the groupby() command from the pandas library to show \n",
    "    # the number of cells in each predicted type\n",
    "    print(adata.obs.groupby([\"free_annotation\"]).size().reset_index(name=\"Number\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of cells in each type vary in this dataset over 3 orders of magnitude\n",
    "# If you performed differential gene expression analysis as-is scanpy would compare each group of cells\n",
    "# versus all other cells, which is currently dominated by NK, Club, and Capillary cells, among others.\n",
    "#\n",
    "# To more accurately identify genes specific to each group, it is important to downsample groups\n",
    "# with large numbers of cells. It is also important to think about what comparison would yeild\n",
    "# cell type specific markers. Cell types are most similar to those in their compartments, so if \n",
    "# you compare them against all other cells, you tend to find their compartment markers. \n",
    "# If, instead, you compare them to cells within their compartment, you often find specific marker genes.\n",
    "#\n",
    "# Both decisions carry risks, for example, the downsampled cells not being representative or finding markers that are\n",
    "# also found in other comparements. But the benefits usually outweigh the downsides\n",
    "# Generally, there is not a single \"correct\" way to calculate differential gene expression and, as always,\n",
    "# your research question should guide you\n",
    "\n",
    "# Create a copy of the adata object to downsample groups with large numbers of cells\n",
    "adata_ds = copy.deepcopy(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python lists are collections of objects (usually strings and numbers)\n",
    "# that can be referenced by their position and appended to\n",
    "# such as the my_list = [1, 'two', 3], where my_list[0] would return 1\n",
    "# and my_list[:1] would return [1, 'two']\n",
    "# Lists can be combined with the \"+\" operator like this:\n",
    "# my_list + ['four', 5, 6] would return [1, 'two', 3, 'four', 5, 6]\n",
    "#\n",
    "# Create an empty list of cells to use in the downsampled adata object\n",
    "cells = []\n",
    "\n",
    "# Loop through each cell type, called with the cat.categories function in pandas\n",
    "for i in adata.obs.free_annotation.cat.categories:\n",
    "    \n",
    "    # Get a list of cells whose free_annotation matches the current cell type\n",
    "    tmp = adata[adata.obs.free_annotation == i].obs_names.to_list()\n",
    "    \n",
    "    # If it has more than 100 cells, randomly sample 100 of them using the sample()\n",
    "    # function in the random library\n",
    "    if len(tmp) > 100:\n",
    "        cells = cells + random.sample(tmp, k=100)\n",
    "    \n",
    "    # If not, take all of them\n",
    "    else:\n",
    "        cells = cells + tmp\n",
    "\n",
    "# Subset adata_ds to the chosen cells\n",
    "adata_ds = adata_ds[cells]\n",
    "adata_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python dictionaries allow us to store information in keys, for exmaple:\n",
    "# my_dict = {'key': value, 'science': 'is', 'really': 'fun'}\n",
    "# my_dict['science'] will return \"is\" and my_dict['really'] will return \"fun\"\n",
    "# In this case we'll use a dict where each \"key\" is a cell type and the information stored\n",
    "# (the \"value\") is a data frame of differentially expressed genes for that cell type\n",
    "marker_genes = {}\n",
    "\n",
    "# Loop through each tissue compartment\n",
    "for i in adata.obs.compartment.cat.categories:\n",
    "    \n",
    "    # Create a temporary adata object that includes only cells from the current tissue compartment\n",
    "    adata_tmp = adata_ds[adata_ds.obs.compartment == i]\n",
    "    \n",
    "    # Identify differentially expressed genes for each cell type within the current tissue compartment\n",
    "    # Uses the same test as Seurat (wilcoxon rank-sum) for p-values, but a different\n",
    "    # correction for the false discovery correction (Benjamini-hochberg)\n",
    "    sc.tl.rank_genes_groups(adata_tmp,\n",
    "                            groupby=\"free_annotation\",\n",
    "                            method=\"wilcoxon\",\n",
    "                            tie_correct=True)\n",
    "    \n",
    "    # Python has something called comprehension that allows for 1-liner loops\n",
    "    # In the simplest case, something like [print(x) for x in [1, 2, 3]] would print 1, 2 and 3 on separate lines.\n",
    "    # It is equivalent to\n",
    "    #\n",
    "    # for x in [1, 2, 3]:\n",
    "    #    print(x)\n",
    "    #\n",
    "    # In this case, we use two nested loops\n",
    "    # The inner loop, for key in ['names', 'pvals_adj', 'logfoldchanges'], pulls the gene symbols, adjusted p-values,\n",
    "    # and logfoldchanges from the differential gene expression results in the temporary adata object for each\n",
    "    # cell type, which is set by the outer loop, for group in groups. The outer loop then stores the results of the inner\n",
    "    # loop to a temporary dictionary with the cell types name as the key.\n",
    "    result = adata_tmp.uns['rank_genes_groups']\n",
    "    groups = result['names'].dtype.names\n",
    "    tmp = {group: pd.DataFrame({key: result[key][group] for key in ['names', 'pvals_adj', 'logfoldchanges']}) for group in groups}\n",
    "    \n",
    "    # Merge the temporary dict holding the current compartments' cell types differentially expressed genes with the others\n",
    "    marker_genes = {**marker_genes, **tmp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can explore how scanpy stores differentially expressed genes in the \"uns\" shelf\n",
    "# To better understand how the nested for loops above work\n",
    "display(adata_tmp.uns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in gene information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can aide interpetation of the differentially expressed genes by gathering important information about each gene, such as its name and whether its a transcription factor, receptor, ligand, or enzyme or if mutations in it have cause a human disease with mendelian inheritance (and are therefore causal). Choosing good sources is important, many groups have created lists like these and not all are created equal. This tutorial highlights a few we have found quite useful, but we encourage you to explore!\n",
    "\n",
    "Most people get stumpped staring at gene lists and start using gene set enrichment analysis (GSEA), go term analysis, or other similar approaches like DAVID (https://david.ncifcrf.gov). You _can_ do this, and we can discuss offline how, but today we are going to explore alternative ways to explore gene lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to RefSeq using the mygene library (see https://mygene.info for more uses)\n",
    "mg = mygene.MyGeneInfo()\n",
    "\n",
    "# Create a table of gene symbols and their corresponding names with the querymany() function from mygene\n",
    "# You can obtain the unique values from the pandas dataframe with pandas' unique() function\n",
    "# and then convert them to a list (expected by mygene) with pandas' tolist() function\n",
    "symbolToName = mg.querymany(adata.var_names.tolist(),\n",
    "             scopes='symbol,name',\n",
    "             species='human',\n",
    "             fields=\"name\",\n",
    "             as_dataframe=True)\n",
    "\n",
    "# Remove rows where a gene names was not found\n",
    "symbolToName = symbolToName[symbolToName.notfound.isna()]\n",
    "\n",
    "# Save the data frame index to a column\n",
    "symbolToName['query'] = symbolToName.index.to_series()\n",
    "\n",
    "# Remove rows with duplicates in the query column\n",
    "# Keeps the first instance by default\n",
    "symbolToName.drop_duplicates(subset=\"query\", inplace=True)\n",
    "\n",
    "# Remove extra columns from the table\n",
    "symbolToName = symbolToName[['name', 'query']]\n",
    "\n",
    "symbolToName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbolToName[symbolToName.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a list of transcription factors (also includes their family) from the AnimalTFDB\n",
    "tfs = pd.read_csv(os.path.join(pwd, 'dbs', 'AnimalTFDB.tsv'), sep=\"\\t\")\n",
    "\n",
    "# Set the index of the table to the gene symbols\n",
    "tfs.index = tfs.Symbol\n",
    "tfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a list of protein ligands from the Guide to Pharmacology (GtP) database\n",
    "# The information we want is spread across two tab separated values tables\n",
    "# We set the index of both to the column that has the GtP IDs\n",
    "ligands = pd.read_csv(os.path.join(pwd, 'dbs', 'GtP_ligands.tsv'), sep=\"\\t\", index_col=0)\n",
    "GtPToHGNC = pd.read_csv(os.path.join(pwd, 'dbs', 'GtP_to_HGNC_mapping.tsv'), sep=\"\\t\", index_col=3)\n",
    "\n",
    "# Merge the tables with pandas' merge() function based on the index of both tables, keeping\n",
    "# only those that they have in commmon\n",
    "ligands = ligands.merge(GtPToHGNC, how=\"inner\", left_index=True, right_index=True, copy=False)\n",
    "\n",
    "# The second file also had receptors, we can remove them by looking for \"ligandID\" in the GtP URL\n",
    "# This is another example of a comprehension loop, where 'ligandId' in x will evaluate to True or\n",
    "# False for each URL. This creates a boolean we can use to subset\n",
    "ligands = ligands[['ligandId' in x for x in ligands.gtp_url]]\n",
    "\n",
    "# Set the index of the table to the gene symbols\n",
    "ligands.index = ligands.hgnc_symbol\n",
    "\n",
    "ligands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a list of receptors from the Guide to Pharmacology (GtP) database\n",
    "receptors = pd.read_csv(os.path.join(pwd, 'dbs', 'GtP_receptors.tsv'), sep=\"\\t\")\n",
    "\n",
    "# Set the index of the table to the gene symbols\n",
    "receptors.index = receptors['HGNC symbol']\n",
    "\n",
    "# Remove the enzymes from the list, since we'll build a list for them next from a different source\n",
    "receptors = receptors[receptors.Type != 'enzyme']\n",
    "\n",
    "receptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExPASy does not make reading their database easy, run less ExPASy.tsv in terminal to see why\n",
    "\n",
    "# Create empty dictionaries to hold the enzyme uniprotIDs and classes\n",
    "enzyme_uniprots = []\n",
    "enzyme_classes = []\n",
    "\n",
    "# Compile regular expressions to match patterns in the ExPASy file\n",
    "\n",
    "# ExPASy stores enzyme classes on lines that start with DE and look like:\n",
    "# DE   Enzyme class.\n",
    "# The \"^\" matches the start of the line, followed by DE, followed by 3 spaces\n",
    "# The ([^\\\\.]+) matches any characters that are not a literal period.\n",
    "# In regex, the \".\" matches any character so \"\\\\.\" is used to match literal periods\n",
    "# The parentheses save the characters before the final period to retrieve later as the class\n",
    "re_class = re.compile('^DE   ([^\\\\.]+)\\\\.')\n",
    "\n",
    "# The uniprotIDs are stored on lines that start with DR and look like:\n",
    "# DR   UNIPROT, SYMBOL_SPECIES1;  UNIPROT, SYMBOL_SPECIES2;  UNIPROT, SYMBOL_SPECIES3\n",
    "# Below we split these lines by \";  \" and then use this regex to capture\n",
    "# the uniprotIDs. from \"DR   UNIPROT, SYMBOL_SPECIES1\", \"UNIPROT, SYMBOL_SPECIES2\",\n",
    "# and \"UNIPROT, SYMBOL_SPECIES3\" separately.\n",
    "#\n",
    "# The (?:DR   )? matches the first part of the line, but the \"?:\" keeps regex from\n",
    "# saving the characters for later. the \"?\" outside the parentheses allows the regex to\n",
    "# match even if its not there, since the second and third strings do not have it\n",
    "# ([^,]+) matches characters that are not a comma and saves them, while [^_]+\n",
    "# matches any characters that are not an underscore.\n",
    "re_uniprot = re.compile('(?:^DR   )?([^,]+), [^_]+_HUMAN')\n",
    "\n",
    "# Opems the enzymes file using base python's open() command\n",
    "# The with statement allows us to set the contents to fp and use them in the code below\n",
    "with open(os.path.join(pwd, 'dbs', 'ExPASy.txt')) as fp:\n",
    "    \n",
    "    # Loop through each line with base python's enumerate function\n",
    "    for cnt, line in enumerate(fp):\n",
    "        \n",
    "        # If the line is empty move to the next line\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "            \n",
    "        # If its not empty    \n",
    "        else:\n",
    "            # Test if it matches a class line or a human\n",
    "            enzyme_match = re_class.match(line)\n",
    "            \n",
    "            # If it does\n",
    "            if enzyme_match is not None:\n",
    "                \n",
    "                # Save the enzyme class\n",
    "                enzyme_class = enzyme_match[1]\n",
    "            \n",
    "            # Test if _HUMAN is in the line\n",
    "            if \"_HUMAN\" in line:\n",
    "                \n",
    "                # If it is, split the line by \";  \"\n",
    "                sublines = line.split(';  ')\n",
    "                \n",
    "                # Loop through each piece of the line\n",
    "                for x in sublines:\n",
    "                    \n",
    "                    # Test if the current piece has _HUMAN\n",
    "                    uniprot = re_uniprot.match(x)\n",
    "                    \n",
    "                    # If it does\n",
    "                    if uniprot is not None:\n",
    "                        \n",
    "                        # Append the uniprotID to enzyme_uniprots\n",
    "                        enzyme_uniprots.append(uniprot[1])\n",
    "                        \n",
    "                        # Append the current enzyme_class to enzyme_classes\n",
    "                        # enzyme_class won't change until another DE line\n",
    "                        # So if multiple enzymes entries are under a class\n",
    "                        # They will all get properly assigned\n",
    "                        enzyme_classes.append(enzyme_class)\n",
    "\n",
    "# Create a pandas data frame from the enzyme_symbols and enzyme_classes lists\n",
    "enzymes = pd.DataFrame(data={'uniprot': enzyme_uniprots, 'class': enzyme_classes})\n",
    "\n",
    "# Set the index of the data frame to the uniprotIDs\n",
    "enzymes.index = enzymes.uniprot\n",
    "\n",
    "# Connect to RefSeq using the mygene library (see https://mygene.info for more uses)\n",
    "mg = mygene.MyGeneInfo()\n",
    "\n",
    "# Create a table of uniprotIDs and corresponding gene symbols with the querymany() function from mygene\n",
    "# You can obtain the unique values from the pandas dataframe with pandas' unique() function\n",
    "# and then convert them to a list (expected by mygene) with pandas' tolist() function\n",
    "uniProtToGene = mg.querymany(enzymes.uniprot.unique().tolist(),\n",
    "             scopes='uniprot,symbol',\n",
    "             species='human',\n",
    "             as_dataframe=True)\n",
    "\n",
    "# Remove rows that could not be matched to a gene symbol\n",
    "uniProtToGene = uniProtToGene[uniProtToGene.notfound.isna()]\n",
    "\n",
    "# Remove all columns but the gene symbols\n",
    "uniProtToGene = uniProtToGene['symbol']\n",
    "\n",
    "# Merge the data frame into the enzymes one by their indices (which are the uniprotIDs in both)\n",
    "enzymes = enzymes.merge(uniProtToGene, how=\"inner\", left_index=True, right_index=True)\n",
    "\n",
    "# Set the enzymes data frame index to the gene symbols\n",
    "enzymes.index = enzymes.symbol\n",
    "\n",
    "enzymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the Online Mendelian Inheritance in Man (OMIM) database\n",
    "# It has several commented lines above and below, we can have read_csv ignore them\n",
    "# We can rename the columns (which are very long in the original file) with the names paramter\n",
    "omim = pd.read_csv(os.path.join(pwd, 'dbs', 'OMIM.tsv'),\n",
    "                   sep=\"\\t\",\n",
    "                   comment='#',\n",
    "                   index_col=False,\n",
    "                   names=['chromosome',\n",
    "                          'genomic_start',\n",
    "                          'genomic_end',\n",
    "                          'location',\n",
    "                          'comp_location',\n",
    "                          'mim',\n",
    "                          'mim_symbols',\n",
    "                          'name',\n",
    "                          'symbol',\n",
    "                          'entrezID',\n",
    "                          'ensemblID',\n",
    "                          'comments',\n",
    "                          'phenotypes',\n",
    "                          'mgi'])\n",
    "\n",
    "# Remove entries without a gene symbol\n",
    "omim = omim[omim.symbol.notna()]\n",
    "\n",
    "# Remove entries without a disease\n",
    "omim = omim[omim.phenotypes.notna()]\n",
    "\n",
    "# Set the OMIM data frame index to the gene symbols\n",
    "omim.index = omim.symbol\n",
    "\n",
    "omim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each cell types differential expression list\n",
    "for k, i in marker_genes.items():\n",
    "    \n",
    "    # Set the index of the current marker genes data frame to the gene symbols\n",
    "    i.index = i.names\n",
    "    \n",
    "    # Remove the extra gene symbols column\n",
    "    i.drop(columns=['names'], inplace=True)\n",
    "    \n",
    "    # Create 5 empty columns with every row/gene set to \"\"\n",
    "    i['TF'] = ''\n",
    "    i['Lig'] = ''\n",
    "    i['Rec'] = ''\n",
    "    i['Enz'] = ''\n",
    "    i['OMIM'] = ''\n",
    "    \n",
    "    # If a gene in the marker genes data frame is also on the transcription factor\n",
    "    # ligand, receptor, enzyme, or OMIM lists, set the relevant column and row to True\n",
    "    i.loc[np.intersect1d(i.index.values, tfs.Symbol.values), 'TF'] = True\n",
    "    i.loc[np.intersect1d(i.index.values, ligands.hgnc_symbol.values), 'Lig'] = True\n",
    "    i.loc[np.intersect1d(i.index.values, receptors['HGNC symbol'].values.astype(str)), 'Rec'] = True\n",
    "    i.loc[np.intersect1d(i.index.values, enzymes.symbol.values), 'Enz'] = True\n",
    "    i.loc[np.intersect1d(i.index.values, omim.symbol.values), 'OMIM'] = True\n",
    "    \n",
    "    # Merge in the names we obtained earlier from mygene\n",
    "    i = i.merge(symbolToName, how='left', left_index=True, right_index=True)\n",
    "    \n",
    "    # Remove the extra symbol column added by the merge above\n",
    "    i.drop(columns=['query'], inplace=True)\n",
    "    \n",
    "    marker_genes[k] = i.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at differential gene expression lists with added gene information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a cell types top 100 differentially expressed genes\n",
    "# In this case, we show those for Pericytes\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(marker_genes['Pericyte'].head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain information on the transcription factors in the top 100 differentially expressed genes in pericytes\n",
    "tfs.loc[marker_genes['Pericyte'].iloc[np.where(marker_genes['Pericyte'].TF.head(100) == True)[0]].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain information on the receptors in the top 100 differentially expressed genes in pericytes\n",
    "receptors.loc[marker_genes['Pericyte'].iloc[np.where(marker_genes['Pericyte'].Rec.head(100) == True)[0]].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain information on the ligands in the top 100 differentially expressed genes in pericytes\n",
    "ligands.loc[marker_genes['Pericyte'].iloc[np.where(marker_genes['Pericyte'].Lig.head(100) == True)[0]].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain information on the enzymes in the top 100 differentially expressed genes in pericytes\n",
    "enzymes.loc[marker_genes['Pericyte'].iloc[np.where(marker_genes['Pericyte'].Enz.head(100) == True)[0]].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain information on the OMIM genes in the top 100 differentially expressed genes in pericytes\n",
    "omim.loc[marker_genes['Pericyte'].iloc[np.where(marker_genes['Pericyte'].OMIM.head(100) == True)[0]].index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing biologically motivated hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pericytes are contractile stromal cells associated with microvascular capillaries in many organs that have long been suspected of regulating blood flow, but no one has demonstrated that in lung.\n",
    "\n",
    "We can borrow the molecular logic for contracility from Vascular Smooth Muscle (VSM), which are on larger vessels and are known to regulate blood floow. In VSM, myosins are phosphorylated and dephosphorylated during their duty cycle by kinases and phosphotases, which are regulated by the second messengers cyclic AMP, cyclic GMP, and inostitol 1,4,5-triphosphate. These second messengers are produced and degraded by enzymes that are under the regulation of hormone receptors and can be shared with nearby cells through intercellular gap junctions. Finally, we know contracility requires depolarization of the membrane through calcium influx, which is mediated by voltage gated ion channels.\n",
    "\n",
    "As you run through this section of code, consider: What does relevant pericyte-specific gene expression look like? Given that, how plausible is the idea that pericytes may be involved in regulating blood flow in lung capillaries? And if it is plausible, can we learn anything about molecular mechanisms that may be involved in regulating this process in pericytes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a list of myosin heavy and light chain genes\n",
    "# In this regex ^ matches the start of a string\n",
    "# [OHL] matches O or H or L, [0-9]{1,2} matches any one or two numbers\n",
    "# [A-Z]? matches 0 or 1 capital letters, and $ matches the end of the string\n",
    "re_myosin = re.compile('^MY[OHL][0-9]{1,2}[A-Z]?$')\n",
    "myosin_genes = adata.var_names[[re_myosin.match(x) is not None for x in adata.var_names]].sort_values()\n",
    "print(myosin_genes)\n",
    "\n",
    "# Build a list of the kinases that phosphorylate myosin\n",
    "re_myosin_kin = re.compile('^MYLK[0-9]?$')\n",
    "myosin_kin_genes = adata.var_names[[re_myosin_kin.match(x) is not None for x in adata.var_names]].sort_values()\n",
    "print(myosin_kin_genes)\n",
    "\n",
    "# Build a list of the phosphatases that dephosphorylate myosin\n",
    "re_myosin_phos = re.compile('^PPP1[RC][0-9]{1,2}[A-Z]?$')\n",
    "myosin_phos_genes = adata.var_names[[re_myosin_phos.match(x) is not None for x in adata.var_names]].sort_values()\n",
    "print(myosin_phos_genes)\n",
    "\n",
    "# Use the enzymes list find enzymes that make and degrade second messenger cAMP\n",
    "cAMP_syn_genes = enzymes[['Adenylate cyclase' in x for x in enzymes['class']]].index.sort_values()\n",
    "cAMP_deg_genes = enzymes[[\"3',5'-cyclic-AMP phosphodiesterase\" in x for x in enzymes['class']]].index.sort_values()\n",
    "print(cAMP_syn_genes)\n",
    "print(cAMP_deg_genes)\n",
    "\n",
    "# Use the enzymes list find enzymes that make and degrade second messenger cGMP\n",
    "cGMP_syn_genes = enzymes[['Guanylate cyclase' in x for x in enzymes['class']]].index.sort_values()\n",
    "cGMP_deg_genes = enzymes[[\"3',5'-cyclic-GMP phosphodiesterase\" in x for x in enzymes['class']]].index.sort_values()\n",
    "print(cGMP_syn_genes)\n",
    "print(cGMP_deg_genes)\n",
    "\n",
    "# Use the enzymes list find enzymes that make and degrade second messenger IP3\n",
    "IP3_syn_genes = enzymes[['phospholipase C' in x for x in enzymes['class']]].index.sort_values()\n",
    "IP3_deg_genes = enzymes[[\"Phosphoinositide 5-phosphatase\" in x for x in enzymes['class']]].index.sort_values()\n",
    "print(IP3_syn_genes)\n",
    "print(IP3_deg_genes)\n",
    "\n",
    "# Read in the hormone receptor list for who can trigger second messenger synthases\n",
    "hormones = pd.read_csv(os.path.join(pwd, 'dbs', 'Hormones.csv'), index_col=1)\n",
    "hormones.index\n",
    "\n",
    "# Use receptor list to find voltage gated ion channels needed for contractility\n",
    "vgic_genes = receptors[receptors.Type == \"vgic\"].index\n",
    "print(vgic_genes)\n",
    "\n",
    "# Use receptor list to find gap junctions which can spread second messengers\n",
    "gap_genes = receptors[receptors['Family name'] == \"Connexins and Pannexins\"].index.sort_values()\n",
    "print(gap_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordering the cells by tissue compartment can make it easier to see patterns of gene expression\n",
    "cell_order = ['Club', # Epithelial\n",
    "              'Ciliated',\n",
    "              'Basal',\n",
    "              'Differentiating Basal',\n",
    "              'Goblet',\n",
    "              'Ionocyte',\n",
    "              'Neuroendocrine',\n",
    "              'Alveolar Epithelial Type 1',\n",
    "              'Alveolar Epithelial Type 2',\n",
    "              'Signaling Alveolar Epithelial Type 2',\n",
    "              'Artery', # Endothelial\n",
    "              'Vein',\n",
    "              'Capillary Aerocyte',\n",
    "              'Capillary',\n",
    "              'Capillary Intermediate 1',\n",
    "              'Bronchial Vessel 1',\n",
    "              'Lymphatic',\n",
    "              'Airway Smooth Muscle', # Stromal\n",
    "              'Vascular Smooth Muscle',\n",
    "              'Myofibroblast',\n",
    "              'Fibromyocyte',\n",
    "              'Adventitial Fibroblast',\n",
    "              'Alveolar Fibroblast',\n",
    "              'Lipofibroblast',\n",
    "              'Pericyte',\n",
    "              'B', # Immune\n",
    "              'Plasma',\n",
    "              'CD8+ Memory/Effector T',\n",
    "              'CD8+ Naive T',\n",
    "              'CD4+ Memory/Effector T',\n",
    "              'CD4+ Naive T',\n",
    "              'Natural Killer T',\n",
    "              'Natural Killer',\n",
    "              'Proliferating NK/T', \n",
    "              'Neutrophil',\n",
    "              'Basophil/Mast 1',\n",
    "              'Macrophage',\n",
    "              'Plasmacytoid Dendritic',\n",
    "              'Dendritic',\n",
    "              'Myeloid Dendritic Type 2',\n",
    "              'IGSF21+ Dendritic',\n",
    "              'Classical Monocyte',\n",
    "              'Nonclassical Monocyte',\n",
    "              'Intermediate Monocyte']\n",
    "\n",
    "# Use the set_categories() command part of the cat section of the pandas library\n",
    "# It expects a pandas Index() object, so we convert the list from above to one\n",
    "adata.obs.free_annotation.cat.set_categories(pd.Index(cell_order), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is scanpy's dotplot function, for more usage information see:\n",
    "# https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.dotplot.html#scanpy.pl.dotplot\n",
    "# Plot myosin genes\n",
    "sc.pl.dotplot(adata, var_names = myosin_genes, groupby=\"free_annotation\", mean_only_expressed=True, cmap=\"Greys\", dot_min=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot combined myosin kinase (MYLK) and phosphatase genes (PP1)\n",
    "sc.pl.dotplot(adata, var_names = myosin_kin_genes.union(myosin_phos_genes), groupby=\"free_annotation\", mean_only_expressed=True, cmap=\"Greys\", dot_min=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot combined cAMP synthesis (ADCY) and degredation genes (PDE)\n",
    "sc.pl.dotplot(adata, var_names = cAMP_syn_genes.union(cAMP_deg_genes), groupby=\"free_annotation\", mean_only_expressed=True, cmap=\"Greys\", dot_min=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot combined cGMP synthesis (GUCY) and degredation genes (PDE)\n",
    "sc.pl.dotplot(adata, var_names = cGMP_syn_genes.union(cGMP_deg_genes), groupby=\"free_annotation\", mean_only_expressed=True, cmap=\"Greys\", dot_min=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.dotplot(adata, var_names = IP3_syn_genes.union(IP3_deg_genes), groupby=\"free_annotation\", mean_only_expressed=True, cmap=\"Greys\", dot_min=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.dotplot(adata, var_names = np.intersect1d(hormones.index.to_list(),adata.var_names), groupby=\"free_annotation\", mean_only_expressed=True, cmap=\"Greys\", dot_min=0.05, swap_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.dotplot(adata, var_names = vgic_genes, groupby=\"free_annotation\", mean_only_expressed=True, cmap=\"Greys\", dot_min=0.05, swap_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.dotplot(adata, var_names = gap_genes, groupby=\"free_annotation\", mean_only_expressed=True, cmap=\"Greys\", dot_min=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Does the expression of the various components of contractility support the hypothesis? Did we learn about specific myosins, second messenger enzymes, hormone receptors, ion channels, and gap junctions that are expressed in pericytes? Are some or all pericyte-specific factors we deteced the same as those expressed by Vascular Smooth Muscle cells? If yes, is it possible that pericytes and vascular smooth muscle cells co-opt same factors to perfom similar functions? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many viruses enter our bodies through inhalation, after which they travel down the respiratory tract and then attach to and enter cells to start productive infections. The topic has come to the fore with the global pandemic, with many groups looking at single cell RNA sequencing datasets to identify where the putative SARS-CoV-2 receptor _ACE2_ and accessory protease _TMPRSS2_ are expressed. These genes can be plotted on Violin plots with the code block below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "\n",
    "# We can use violin plots to show the distribution of expression across cell types \n",
    "sc.pl.violin(adata, keys=['ACE2', 'TMPRSS2'], groupby=\"free_annotation\", rotation=90, size=3, linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Many groups have implicated Alveolar Epithelial Type 2 cells as a susceptible cell type, does the expression of _ACE2_ and _TMPRSS2_ support this? Do the data suggest other cell types could also be vulnerable to infection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to zeroing in on a specific virus, we could take a wider view and ask: What does expression of all protein receptors associated with viral entry for humans look like?\n",
    "\n",
    "To do this, we leverage Gene Ontology terms, not for enrichment analysis, but as a starting place for a gene list. After restricting entries associated with the term \"viral entry into host cell\"(http://amigo.geneontology.org/amigo/term/GO:0046718) to human genes, without \"NOT\" qualifiers, and with UniProt as their source, we are left with roughly 100 putative receptors. We then search the contributing database (UniProt) for each gene product and identify the paper(s) that support the gene ontology annotation. From these, we filter out genes with weak evidence and identify the specific virus each receptor facilitates entry for (in some cases more than one). After assembling the list of all viruses with protein receptors (this does not include viruses that use non-protein receptors like sialic acid), we then cultivate metadata on each virus including its family, genus, genome type, size, pathology, and whether the lung is its primary entry site (another common one being oral-fecal).\n",
    "\n",
    "Below, we are reading in two CSVs created by the process described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viral_entry = pd.read_csv(os.path.join(pwd, 'dbs', 'viral_entry.csv'), index_col=0)\n",
    "virus_metadata = pd.read_csv(os.path.join(pwd, 'dbs', 'virus_metadata.csv'), index_col=0)\n",
    "display(viral_entry)\n",
    "display(virus_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rules for cleaning up and shortening the viral names for display purposes\n",
    "vir_reg = {\" ?virus\": \"\",\n",
    "           \" ?human ?\": \"\",\n",
    "           \" ?subgroup\": \"\", \n",
    "           \" ?type\": \"\",\n",
    "           \" +$\": \"\",\n",
    "           \"simplex ?\": \"\",\n",
    "           \"Immunodeficiency\": \"HIV\",\n",
    "           \"Mammalian\": \"Mam\",\n",
    "           \"Hepatitis\": \"Hep\",\n",
    "           \"Japanese\": \"Jp\",\n",
    "           \"Venezuelan\": \"Vz\",\n",
    "           \"Adeno-associated\": \"AAV\",\n",
    "           \"Respiratory syncytial\": \"RSV\",\n",
    "           \"Rift valley fever\": \"RVF\",\n",
    "           \"Influenza\": \"Flu\"}\n",
    "\n",
    "# In python we can create custom functions that perform tasks on inputs\n",
    "# and then return the outputs. The functions we have been using from pandas\n",
    "# scanpy, velocyto, and more are all custom functions created by users\n",
    "#\n",
    "# You can define functions with \"def\" like so:\n",
    "# def function_name(input_varable1, input_variable2, ...):\n",
    "#    return task to perform with input_varable1 and input_variable2\n",
    "#\n",
    "# One example:\n",
    "# def add_a_comma(word1, word2):\n",
    "#    return \",\".join(word1, word2)\n",
    "#\n",
    "# where add_a_comma('Travaglini', 'Kyle') would return 'Travaglini,Kyle'\n",
    "#\n",
    "# Function to loop through virus and apply virus renaming rules using the\n",
    "# sub() function from the re library. re.I is a special flag that tells\n",
    "# sub() to ignore case when searching for words to replace.\n",
    "def replace_all(dict, text):\n",
    "    for i, j in dict.items():\n",
    "        text = re.sub(i, j, text, flags=re.I)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the viruses whose primary route of infection is through the lung\n",
    "# versus through other avenues into different lists\n",
    "lung_viruses = virus_metadata[virus_metadata['Lung entry'] == True].index.tolist()\n",
    "other_viruses = virus_metadata[virus_metadata['Lung entry'] != True].index.tolist()\n",
    "\n",
    "# Create empty lists to hold genes and viruses that enter through the lungs\n",
    "lung_entry_genes = []\n",
    "lung_entry_viruses = []\n",
    "\n",
    "# Create empty lists to hold genes and viruses that enter other ways\n",
    "other_entry_genes = []\n",
    "other_entry_viruses  = []\n",
    "\n",
    "# Loop through each viral receptor\n",
    "for i in viral_entry.index:\n",
    "    \n",
    "    # Subset the viral_entry table to the current viral receptor\n",
    "    tmp = viral_entry[viral_entry.index == i]\n",
    "    \n",
    "    # Use nested list comprehension to identify **respiratory** viruses the current receptor facilitates entry for,\n",
    "    # clean the name up with replace_all, and raise the first letter in each name to uppercase\n",
    "    virus_tmp = [k[:1].upper() + k[1:] for k in [replace_all(vir_reg, j) for j in tmp.loc[i,:][[x in lung_viruses for x in tmp.iloc[0,:]]].tolist()]]\n",
    "    \n",
    "    # Sort the cleaned **respiratory** virus names alphabetically\n",
    "    virus_tmp.sort()\n",
    "    \n",
    "    # If the current receptor facilities entry for repsiratory virus(es),\n",
    "    # add it and the viruses to the lung list\n",
    "    if len(virus_tmp) > 0:\n",
    "        lung_entry_genes.append(i)\n",
    "        lung_entry_viruses.append(\"   \".join(virus_tmp))\n",
    "\n",
    "    # Use nested list comprehension to identify **non-respiratory** viruses the current receptor facilitates entry for,\n",
    "    # clean the name up with replace_all, and raise the first letter in each name to uppercase    \n",
    "    virus_tmp = [k[:1].upper() + k[1:] for k in [replace_all(vir_reg, j) for j in tmp.loc[i,:][[x in other_viruses for x in tmp.iloc[0,:]]].tolist()]]\n",
    "    \n",
    "    # Sort the cleaned **non-respiratory** virus names alphabetically\n",
    "    virus_tmp.sort()\n",
    "    \n",
    "    # If the current receptor facilities entry for **non-repsiratory** virus(es),\n",
    "    # add it and the viruses to the other list\n",
    "    if len(virus_tmp) > 0:\n",
    "        other_entry_genes.append(i)\n",
    "        other_entry_viruses.append(\"   \".join(virus_tmp))\n",
    "\n",
    "# Create dataframes for the respiratory and non-respiratory viral entry receptors and\n",
    "# sort them based on the cleaned virus names\n",
    "lung_entry = pd.DataFrame(data={'viruses': lung_entry_viruses}, index=lung_entry_genes)\n",
    "lung_entry.sort_values(by=\"viruses\", axis=0, inplace=True)\n",
    "other_entry = pd.DataFrame(data={'viruses': other_entry_viruses}, index=other_entry_genes)\n",
    "other_entry.sort_values(by=\"viruses\", axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the receptors and viruses for respiratory viruses\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(lung_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "\n",
    "# Plot the receptors for respiratory viruses\n",
    "sc.pl.dotplot(adata, var_names = lung_entry.index, groupby=\"free_annotation\", mean_only_expressed=True, cmap=\"Greys\", dot_min=0.05, swap_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the receptors and viruses for non-respiratory viruses\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(other_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 14]\n",
    "\n",
    "# Plot the receptors for non-respiratory viruses\n",
    "sc.pl.dotplot(adata, var_names = other_entry.index, groupby=\"free_annotation\", mean_only_expressed=True, cmap=\"Greys\", dot_min=0.05, swap_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:** Do you notice any interesting expression patterns for respiratory and non-respiratory viruses? Why might we have included the non-respiratory viruses here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is up to you! The HLCA SmartSeq2 dataset contains cell types across all the major tissue compartments for the lung. Come up with a question, either directed like Example 1 or more open like Example 2, then practice making a gene list to address it. Once you have the gene list, visualize the genes using whatever plotting functions you feel are best suited to answer your question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What was your question? What was the answer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
